# --- 1. Imports ---
# Streamlit is the core library for creating the interactive web application UI.
import streamlit as st
# OpenAI library for interacting with the Assistants API.
import openai
# Time library, used here to pause between API status checks.
import time
# JSON library, used for parsing function arguments provided by the Assistant.
import json
# Typing library for type hints, improving code readability and maintainability.
from typing import Dict, List
# Dotenv for loading environment variables (like API keys) from a .env file.
from dotenv import load_dotenv
# OS library for accessing environment variables.
import os

# Import the semantic search function from our utility module.
# This function connects our high-level assistant to the low-level document retrieval logic.
from contracts_utils import search_contract

# --- 2. Configuration and Setup ---
# Load environment variables from a .env file in the project root.
load_dotenv()
# Securely retrieve the OpenAI API key from environment variables.
openai_api_key = os.environ['OPENAI_API_KEY']

# Configure the Streamlit page. This should be the first Streamlit command in the script.
# It sets the browser tab title and icon.
st.set_page_config(page_title="Assistant API Chatbot", page_icon="ðŸ¤–")

# --- 3. Streamlit Session State Initialization ---
# Streamlit scripts rerun from top to bottom with every user interaction.
# `st.session_state` is a dictionary-like object that persists across these reruns for a single user session.
# It's essential for maintaining state, like conversation history.

# Initialize the message history list in the session state if it doesn't already exist.
if 'messages' not in st.session_state:
    st.session_state.messages = []

# Initialize the OpenAI Thread ID. A thread represents a single conversation.
# We store it in the session state to continue the same conversation across interactions.
if 'thread_id' not in st.session_state:
    st.session_state.thread_id = None


# --- 4. Tool Definition ---
# This is the actual Python function that the OpenAI Assistant is configured to call.
# When the assistant determines it needs to search for a contract, it will invoke this function by name.
def semantic_contract_search(query: str) -> List[Dict]:
    """
    Acts as a bridge between the OpenAI Assistant and our local search function.
    The assistant will provide the 'query' argument.

    Args:
        query (str): The search query generated by the Assistant.

    Returns:
        List[Dict]: A list of contract documents found by the search function.
    """
    print(f"Finding the contract with the query: {query}")
    # This calls the function from 'contracts_utils.py' to perform the actual embedding search.
    return search_contract(query)


# --- 5. OpenAI Assistant Configuration ---
# Define constants for the API key and the Assistant ID.
# The ASSISTANT_ID points to an Assistant you have already created in your OpenAI account dashboard.
# That Assistant has been configured with instructions and knows about the `semantic_contract_search` tool.
ASSISTANT_ID = "asst_nqHxNFqXR5HHhbtGXIkwr6FW"  # This is your specific assistant ID

# Initialize the OpenAI client.
client = openai.Client(api_key=openai_api_key)


# --- 6. Assistants API Helper Functions ---
def create_thread() -> str:
    """
    Creates a new conversation thread in the OpenAI Assistants API.

    Returns:
        str: The unique ID of the newly created thread.
    """
    thread = client.beta.threads.create()
    return thread.id


def process_message(user_input: str, thread_id: str) -> str:
    """
    Handles the entire lifecycle of a message: sending it, running the assistant,
    handling tool calls, and retrieving the final response.

    Args:
        user_input (str): The message typed by the user.
        thread_id (str): The ID of the current conversation thread.

    Returns:
        str: The assistant's final text response.
    """
    # 1. Add the user's message to the existing thread.
    client.beta.threads.messages.create(
        thread_id=thread_id,
        role="user",
        content=user_input
    )

    # 2. Create a "Run" to process the thread with the specified assistant.
    # A Run is a single attempt by an Assistant to answer a user's prompt.
    run = client.beta.threads.runs.create(
        thread_id=thread_id,
        assistant_id=ASSISTANT_ID
    )

    # 3. Poll the API to check the status of the Run until it's completed or requires action.
    while True:
        run_status = client.beta.threads.runs.retrieve(
            thread_id=thread_id,
            run_id=run.id
        )

        # 4. Handle the 'requires_action' state for Tool Calling.
        if run_status.status == 'requires_action':
            tool_calls = run_status.required_action.submit_tool_outputs.tool_calls
            tool_outputs = []

            for tool_call in tool_calls:
                # Check if the assistant wants to call our specific search function.
                if tool_call.function.name == "semantic_contract_search":
                    # The arguments are provided as a JSON string, so we parse them.
                    arguments = json.loads(tool_call.function.arguments)
                    query = arguments.get("query", "")

                    # Execute our local Python function with the arguments from the assistant.
                    result = semantic_contract_search(query)

                    # Format the output to be sent back to the assistant.
                    tool_outputs.append({
                        "tool_call_id": tool_call.id,
                        "output": str(result)  # The output must be a string.
                    })

            # 5. Submit the results of the tool calls back to the Assistant.
            client.beta.threads.runs.submit_tool_outputs(
                thread_id=thread_id,
                run_id=run.id,
                tool_outputs=tool_outputs
            )

        # 6. Check if the Run is completed.
        elif run_status.status == 'completed':
            break  # Exit the loop.

        # 7. Handle failure cases.
        elif run_status.status in ['failed', 'cancelled']:
            st.error(f"Run failed or cancelled: {run_status.status}")
            return None

        # Wait for a second before checking the status again to avoid spamming the API.
        time.sleep(1)

    # 8. Retrieve the messages from the thread after the Run is complete.
    messages = client.beta.threads.messages.list(thread_id=thread_id)
    # The latest message is at the top of the list (index 0).
    return messages.data[0].content[0].text.value


def main():
    """
    The main function that defines the Streamlit user interface and application logic.
    """
    st.title("ðŸ“§ Contract Agent")
    st.write("Ask me everything about the contracts.")

    # Create a new conversation thread if one doesn't exist for the current session.
    if not st.session_state.thread_id:
        st.session_state.thread_id = create_thread()

    # Create the chat input box at the bottom of the screen.
    user_input = st.chat_input("Write here...")

    # Display the existing conversation messages from the session state.
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])

    # This block executes only when the user types something and presses Enter.
    if user_input:
        # Display the user's new message immediately.
        with st.chat_message("user"):
            st.write(user_input)
        # Add the user's message to our session state history.
        st.session_state.messages.append({"role": "user", "content": user_input})

        # Display the assistant's response.
        with st.chat_message("assistant"):
            # Use a placeholder to show a "thinking" animation or message.
            response_placeholder = st.empty()
            # Process the user's message and get the assistant's response. This is the blocking call.
            response = process_message(user_input, st.session_state.thread_id)
            # Update the placeholder with the final response.
            response_placeholder.write(response)
        # Add the assistant's response to the session state history.
        st.session_state.messages.append({"role": "assistant", "content": response})


# This standard Python construct ensures that the main() function is called when
# the script is executed, e.g., via `streamlit run your_script_name.py`.
if __name__ == "__main__":
    main()